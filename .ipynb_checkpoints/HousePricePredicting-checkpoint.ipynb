{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8225268-64db-49eb-b24d-9101c07e8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv and check the data \n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93162bb3-bd09-4869-903f-d088d57e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data washing\n",
    "file_name = r\"./housing.csv\"\n",
    "data = pd.read_csv(file_name)\n",
    "# data.drop_duplicates([\"ocean_proximity\"])  observe the data set \n",
    "\n",
    "split_rate = 0.8 # the split partial of training set and testing set\n",
    "train_path = \"train_housing.csv\" \n",
    "test_path = \"test_housing.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92b5093a-1bcc-4abc-8124-19db55a76c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is there any NA value\n",
    "data.isna().sum()\n",
    "\n",
    "def str2number(str):\n",
    "    \"\"\"convert the string value of ocean_proximity to number and train\"\"\"\n",
    "    if str == \"ISLAND\":\n",
    "        return 0\n",
    "    elif str == \"NEAR OCEAN\":\n",
    "        return 1\n",
    "    elif str == \"NEAR BAY\":\n",
    "        return 2\n",
    "    elif str == \"<1H OCEAN\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "    data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "data.columns[0]\n",
    "data.loc[:, \"ocean_proximity\"]\n",
    "\n",
    "def save_data(data, file_name):\n",
    "    data.to_csv(file_name, index=False)\n",
    "\n",
    "def split_data(data, split_rate, path):\n",
    "    \"split the original dataframe and save to train_file_name file\"\n",
    "    tmp = int(len(data) * split_rate)\n",
    "    train_data = data[0:tmp]\n",
    "    test_data = data[tmp:]\n",
    "    train_path, test_path = path\n",
    "    save_data(train_data, train_path)\n",
    "    save_data(test_data, test_path)\n",
    "\n",
    "split_data(data, split_rate, (train_path, test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bc5cabd-6457-4a5d-8566-32190f6b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class housedataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = load_data(filename)\n",
    "        self.column_length = len(self.data.columns)\n",
    "        self.data_features = self.data.iloc[:,[x for x in range(self.column_length) if self.data.columns[x] != \"median_house_value\"]]\n",
    "        self.targets = self.data.loc[:, \"median_house_value\"]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # how to extract the data and labels from the whole data\n",
    "\n",
    "        data_features, targets = self.data_features.iloc[index], self.targets.iloc[index] # index first\n",
    "\n",
    "        # print(data_features.values.shape)\n",
    "\n",
    "        targets = targets if type(targets) != pd.Series else targets.values\n",
    "\n",
    "        data = torch.tensor(data_features.values, dtype=torch.float32) # convert dataframe into tensor\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "413a8e4f-98f3-4a6d-a137-0ce4ced28f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "lr = 0.1\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b0a21ee-f780-4e14-88d2-4b200e88aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 9])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "# dataset = housedataset(filename) # use our own value to make dataset\n",
    "\n",
    "train_set = housedataset(train_path)\n",
    "test_set = housedataset(test_path)\n",
    "\n",
    "# this operation is really wrong !!!!! The train_set is not dataset\n",
    "# train_set = dataset[0:int(split_rate * len(dataset))]\n",
    "# test_set = dataset[int(split_rate * len(dataset)) : ]\n",
    "\n",
    "# batchsize = 64\n",
    "\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size, shuffle=True, drop_last=True)\n",
    "test_data = DataLoader(test_set, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# test the data loader\n",
    "for data in train_data:\n",
    "    values, targets = data\n",
    "    print(values.shape)\n",
    "    # print(targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbf353a8-213b-48ab-973f-b6aa24b138eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4128"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8114d39-ec66-4903-b316-5a5128568d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function to solve the MSELoss's Nan situation\n",
    "class price_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        loss_metric = (x-y)/x\n",
    "        return loss_metric.sum() # if x is very big the loss is almost 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9488176-ff22-4104-a2cb-6ce6e835aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_weight_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df76ad42-f190-4162-9478-1e5a8acd5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "class Housing(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"consider the dataset is just 17777 numbers\n",
    "        so the neural network is very simple\n",
    "        \"\"\"\n",
    "        super(Housing, self).__init__()\n",
    "        self.lin1 = nn.Linear(9, 20) \n",
    "        self.lin2 =nn.Linear(20, 5)\n",
    "        self.lin3 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x)) # add relu layer\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e51f79b-2046-47cb-ab6e-a590e61ac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = Housing()\n",
    "house.apply(xavier_weight_init)\n",
    "house.to(device)\n",
    "# define loss function\n",
    "# loss_fn = nn.MSELoss().to(device)\n",
    "loss_fn = price_loss().to(device)\n",
    "\n",
    "optim = torch.optim.SGD(house.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75a9f433-f11f-4718-acec-088a4c93ab2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mhouse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mreshape(res\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(res, targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[68], line 13\u001b[0m, in \u001b[0;36mHousing.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)) \u001b[38;5;66;03m# add relu layer\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(epochs):\n",
    "    house.train() # start the training model\n",
    "    for i, (values, targets) in enumerate(train_data):\n",
    "        values, targets = values.to(device), targets.to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        res = house(values)\n",
    "        targets = targets.reshape(res.shape)\n",
    "        train_loss = loss_fn(res, targets)\n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"train_loss:\", train_loss)\n",
    "            \n",
    "    house.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = torch.tensor(0.0)\n",
    "        num = 0\n",
    "        for (values, targets) in test_data:\n",
    "            vluea, targets = values.to(device), targets.to(device)\n",
    "            \n",
    "            res = house(values)\n",
    "            targets = targets.reshape(res.shape)\n",
    "            train_loss = loss_fn(res, targets)\n",
    "\n",
    "            total_loss += train_loss\n",
    "            num += 1\n",
    "        print(\"\\n test: \\n total_loss is {}, avg_loss is {} \\n\".format(total_loss, total_loss / num))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027f779-7993-431d-90ad-31a43470549b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
