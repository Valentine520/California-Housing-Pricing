{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a8225268-64db-49eb-b24d-9101c07e8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv and check the data \n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "93162bb3-bd09-4869-903f-d088d57e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data washing\n",
    "file_name = r\"./housing.csv\"\n",
    "data = pd.read_csv(file_name)\n",
    "# data.drop_duplicates([\"ocean_proximity\"])  observe the data set \n",
    "\n",
    "split_rate = 0.8 # the split partial of training set and testing set\n",
    "train_path = \"train_housing.csv\" \n",
    "test_path = \"test_housing.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "92b5093a-1bcc-4abc-8124-19db55a76c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is there any NA value\n",
    "data.isna().sum()\n",
    "\n",
    "def str2number(str):\n",
    "    \"\"\"convert the string value of ocean_proximity to number and train\"\"\"\n",
    "    if str == \"ISLAND\":\n",
    "        return 0\n",
    "    elif str == \"NEAR OCEAN\":\n",
    "        return 1\n",
    "    elif str == \"NEAR BAY\":\n",
    "        return 2\n",
    "    elif str == \"<1H OCEAN\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "    data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "data.columns[0]\n",
    "data.loc[:, \"ocean_proximity\"]\n",
    "\n",
    "def save_data(data, file_name):\n",
    "    data.to_csv(file_name, index=False)\n",
    "\n",
    "def split_data(data, split_rate, path):\n",
    "    \"split the original dataframe and save to train_file_name file\"\n",
    "    tmp = int(len(data) * split_rate)\n",
    "    train_data = data[0:tmp]\n",
    "    test_data = data[tmp:]\n",
    "    train_path, test_path = path\n",
    "    save_data(train_data, train_path)\n",
    "    save_data(test_data, test_path)\n",
    "\n",
    "split_data(data, split_rate, (train_path, test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2bc5cabd-6457-4a5d-8566-32190f6b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class housedataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = load_data(filename)\n",
    "        self.column_length = len(self.data.columns)\n",
    "        self.data_features = self.data.iloc[:,[x for x in range(self.column_length) if self.data.columns[x] != \"median_house_value\"]]\n",
    "        self.targets = self.data.loc[:, \"median_house_value\"]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # how to extract the data and labels from the whole data\n",
    "\n",
    "        data_features, targets = self.data_features.iloc[index], self.targets.iloc[index] # index first\n",
    "\n",
    "        # print(data_features.values.shape)\n",
    "\n",
    "        targets = targets if type(targets) != pd.Series else targets.values\n",
    "\n",
    "        data = torch.tensor(data_features.values, dtype=torch.float32) # convert dataframe into tensor\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "413a8e4f-98f3-4a6d-a137-0ce4ced28f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "epochs = 100\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "lr = 0.1\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4b0a21ee-f780-4e14-88d2-4b200e88aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 9])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "# dataset = housedataset(filename) # use our own value to make dataset\n",
    "\n",
    "train_set = housedataset(train_path)\n",
    "test_set = housedataset(test_path)\n",
    "\n",
    "# this operation is really wrong !!!!! The train_set is not dataset\n",
    "# train_set = dataset[0:int(split_rate * len(dataset))]\n",
    "# test_set = dataset[int(split_rate * len(dataset)) : ]\n",
    "\n",
    "# batchsize = 64\n",
    "\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size, shuffle=True, drop_last=True)\n",
    "test_data = DataLoader(test_set, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# test the data loader\n",
    "for data in train_data:\n",
    "    values, targets = data\n",
    "    print(values.shape)\n",
    "    # print(targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bbf353a8-213b-48ab-973f-b6aa24b138eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4128"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a8114d39-ec66-4903-b316-5a5128568d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function to solve the MSELoss's Nan situation\n",
    "class price_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        loss_metric = torch.square((x-y)/x)\n",
    "        return loss_metric.sum() # if x is very big the loss is almost 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b9488176-ff22-4104-a2cb-6ce6e835aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_weight_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "df76ad42-f190-4162-9478-1e5a8acd5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "class Housing(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"consider the dataset is just 17777 numbers\n",
    "        so the neural network is very simple\n",
    "        \"\"\"\n",
    "        super(Housing, self).__init__()\n",
    "        self.lin1 = nn.Linear(9, 20) \n",
    "        self.lin2 =nn.Linear(20, 5)\n",
    "        self.lin3 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x)) # add relu layer\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6e51f79b-2046-47cb-ab6e-a590e61ac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = Housing()\n",
    "house.apply(xavier_weight_init)\n",
    "house.to(device)\n",
    "# define loss function\n",
    "# loss_fn = nn.MSELoss().to(device)\n",
    "loss_fn = price_loss().to(device)\n",
    "\n",
    "optim = torch.optim.Adam(house.parameters(), lr=lr)\n",
    "batch_num = len(train_set) // batch_size # how much batch during single epoch \n",
    "batch_num / 10\n",
    "limitation = 5000\n",
    "model_file_name = \"housing.params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "75a9f433-f11f-4718-acec-088a4c93ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(net, train_loader, test_loader, loss=nn.MSELoss(), optim=None, epochs=10, limitation=0):\n",
    "    if optim == None:\n",
    "        optim = torch.optim.Adam(net.parameters())\n",
    "    \n",
    "    animator = d2l.Animator(xlim=(1, epochs), ylim=(1, limitation), legend=[\"train_loss\", \"test_loss\"])\n",
    "    metric = d2l.Accumulator(2)\n",
    "    # training the model\n",
    "    for epoch in range(epochs):\n",
    "        house.train() # start the training model\n",
    "        metric.reset()\n",
    "        for i, (values, targets) in enumerate(train_loader):\n",
    "            values, targets = values.to(device), targets.to(device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            res = house(values)\n",
    "            targets = targets.reshape(res.shape)\n",
    "            train_loss = loss_fn(res, targets)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            metric.add(train_loss.cpu(), 1)\n",
    "            if (i+1) % (batch_num // 10) == 0 or ((i-1)==batch_num):\n",
    "                avg_loss = metric[0] / metric[1]\n",
    "                avg_loss = (limitation if avg_loss > limitation else avg_loss)\n",
    "                animator.add(epoch + 1 + i / batch_num, (avg_loss, None))\n",
    "                \n",
    "        house.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = torch.tensor(0.0, device=device)\n",
    "            num = 0\n",
    "            for (values, targets) in test_loader:\n",
    "                values, targets = values.to(device), targets.to(device)\n",
    "                \n",
    "                res = house(values)\n",
    "                targets = targets.reshape(res.shape)\n",
    "                train_loss = loss_fn(res, targets)\n",
    "    \n",
    "                total_loss += train_loss\n",
    "                num += 1\n",
    "            avg_loss  = (limitation if total_loss / num > limitation else total_loss.cpu() / num)\n",
    "            \n",
    "            animator.add(epoch + 1, (None, avg_loss))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "262b94f2-1178-4475-bd06-f7db7adacdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(model_file_name):\n",
    "    house.load_state_dict(torch.load(model_file_name))\n",
    "else:\n",
    "    training(net=house, train_loader=train_data, test_loader=test_data\n",
    "         , loss=loss_fn, optim=optim, epochs=epochs, limitation=4000)\n",
    "    torch.save(house.state_dict(), \"housing.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e3ce4e99-6742-4a42-a75c-a35af406bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_compare = [[]] * 2\n",
    "origin = []\n",
    "predict = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (values, targets) in test_data:\n",
    "        values, targets = values.to(device), targets.to(device)\n",
    "        res = torch.squeeze(house(values), 1)\n",
    "        origin.extend(res.tolist())\n",
    "        predict.extend(targets.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ba52e97c-c019-410c-ac84-e4786f944543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the final num is  2133\n",
      "total num is  4096\n"
     ]
    }
   ],
   "source": [
    "def compare(origin, object):\n",
    "    num = 0\n",
    "    total = 0\n",
    "    for x, y in zip(origin, object):\n",
    "        total = total + 1\n",
    "        if np.abs(x - y) / x > 0.5:\n",
    "            num = num + 1\n",
    "    print(\"the final num is \", num)\n",
    "    print(\"total num is \", total)\n",
    "compare(origin, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "05e9877c-fbad-4f2d-a2f4-adf29bb1343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in zip(origin, predict):\n",
    "#     print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249b37e-a4bc-45f2-ba3b-e041d93c3bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
