{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8225268-64db-49eb-b24d-9101c07e8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv and check the data \n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93162bb3-bd09-4869-903f-d088d57e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data washing\n",
    "file_name = r\"./housing.csv\"\n",
    "data = pd.read_csv(file_name)\n",
    "# data.drop_duplicates([\"ocean_proximity\"])  observe the data set \n",
    "\n",
    "split_rate = 0.7 # the split partial of training set and testing set\n",
    "train_path = \"train_housing.csv\" \n",
    "test_path = \"test_housing.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b5093a-1bcc-4abc-8124-19db55a76c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is there any NA value\n",
    "data.isna().sum()\n",
    "\n",
    "def str2number(str):\n",
    "    \"\"\"convert the string value of ocean_proximity to number and train\"\"\"\n",
    "    if str == \"ISLAND\":\n",
    "        return 0\n",
    "    elif str == \"NEAR OCEAN\":\n",
    "        return 1\n",
    "    elif str == \"NEAR BAY\":\n",
    "        return 2\n",
    "    elif str == \"<1H OCEAN\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data[\"ocean_proximity\"] = data[\"ocean_proximity\"].map(str2number)\n",
    "    data[\"total_bedrooms\"].interpolate(\"linear\", inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "data.columns[0]\n",
    "data.loc[:, \"ocean_proximity\"]\n",
    "\n",
    "def save_data(data, file_name):\n",
    "    data.to_csv(file_name, index=False)\n",
    "\n",
    "def split_data(data, split_rate, path):\n",
    "    \"split the original dataframe and save to train_file_name file\"\n",
    "    tmp = int(len(data) * split_rate)\n",
    "    train_data = data[0:tmp]\n",
    "    test_data = data[tmp:]\n",
    "    train_path, test_path = path\n",
    "    save_data(train_data, train_path)\n",
    "    save_data(test_data, test_path)\n",
    "\n",
    "split_data(data, split_rate, (train_path, test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc5cabd-6457-4a5d-8566-32190f6b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class housedataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = load_data(filename)\n",
    "        self.column_length = len(self.data.columns)\n",
    "        self.data_features = self.data.iloc[:,[x for x in range(self.column_length) if self.data.columns[x] != \"median_house_value\"]]\n",
    "        self.targets = self.data.loc[:, \"median_house_value\"]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # how to extract the data and labels from the whole data\n",
    "\n",
    "        data_features, targets = self.data_features.iloc[index], self.targets.iloc[index] # index first\n",
    "\n",
    "        # print(data_features.values.shape)\n",
    "\n",
    "        targets = targets if type(targets) != pd.Series else targets.values\n",
    "\n",
    "        data = torch.tensor(data_features.values, dtype=torch.float32) # convert dataframe into tensor\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "413a8e4f-98f3-4a6d-a137-0ce4ced28f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "epochs = 1000\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "lr = 0.01\n",
    "batch_size = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b0a21ee-f780-4e14-88d2-4b200e88aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 9])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "# dataset = housedataset(filename) # use our own value to make dataset\n",
    "\n",
    "train_set = housedataset(train_path)\n",
    "test_set = housedataset(test_path)\n",
    "\n",
    "# this operation is really wrong !!!!! The train_set is not dataset\n",
    "# train_set = dataset[0:int(split_rate * len(dataset))]\n",
    "# test_set = dataset[int(split_rate * len(dataset)) : ]\n",
    "\n",
    "# batchsize = 64\n",
    "\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size, shuffle=True, drop_last=True)\n",
    "test_data = DataLoader(test_set, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# test the data loader\n",
    "for data in train_data:\n",
    "    values, targets = data\n",
    "    print(values.shape)\n",
    "    # print(targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df76ad42-f190-4162-9478-1e5a8acd5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "class Housing(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Housing, self).__init__()\n",
    "        self.lin1 = nn.Linear(9, 20) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 =nn.Linear(20, 5)\n",
    "        self.lin3 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "house = Housing()\n",
    "\n",
    "# define loss function\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "optim = torch.optim.SGD(house.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75a9f433-f11f-4718-acec-088a4c93ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6060e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is inf, avg_loss is inf \n",
      "\n",
      "tensor(inf, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 5.737605920186806e+36, avg_loss is 1.9125353595477103e+35 \n",
      "\n",
      "tensor(1.9125e+35, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 3.1281356319193497e+35, avg_loss is 1.0427118195359147e+34 \n",
      "\n",
      "tensor(1.0427e+34, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 1.7054566369077752e+34, avg_loss is 5.684855482149668e+32 \n",
      "\n",
      "tensor(5.6849e+32, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 9.29813513914646e+32, avg_loss is 3.099378492548563e+31 \n",
      "\n",
      "tensor(3.0994e+31, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 5.06932674238806e+31, avg_loss is 1.6897756110191656e+30 \n",
      "\n",
      "tensor(1.6898e+30, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 2.763790900446718e+30, avg_loss is 9.21263620889262e+28 \n",
      "\n",
      "tensor(9.2126e+28, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 1.5068155307739361e+29, avg_loss is 5.02271843591312e+27 \n",
      "\n",
      "tensor(5.0227e+27, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 8.215146202466296e+27, avg_loss is 2.7383820797865948e+26 \n",
      "\n",
      "tensor(2.7384e+26, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 4.478884956361701e+26, avg_loss is 1.4929616367482803e+25 \n",
      "\n",
      "tensor(1.4930e+25, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 2.4418833656555844e+25, avg_loss is 8.139611411005532e+23 \n",
      "\n",
      "tensor(8.1396e+23, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 1.3313129048994763e+24, avg_loss is 4.437709713022252e+22 \n",
      "\n",
      "tensor(4.4377e+22, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 7.2583110071246544e+22, avg_loss is 2.419437021139883e+21 \n",
      "\n",
      "tensor(2.4194e+21, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 3.957233898101999e+21, avg_loss is 1.3190779425777517e+20 \n",
      "\n",
      "tensor(1.3191e+20, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 2.1575150203457818e+20, avg_loss is 7.191716991038652e+18 \n",
      "\n",
      "tensor(7.1915e+18, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 1.1763519874435908e+19, avg_loss is 3.921173199852667e+17 \n",
      "\n",
      "tensor(3.9211e+17, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 6.415355541517763e+17, avg_loss is 2.1384517612732416e+16 \n",
      "\n",
      "tensor(2.1378e+16, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 3.502002301776691e+16, avg_loss is 1167334127435776.0 \n",
      "\n",
      "tensor(1.1660e+15, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 1920080833150976.0, avg_loss is 64002692481024.0 \n",
      "\n",
      "tensor(6.3527e+13, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 107493174804480.0, avg_loss is 3583105826816.0 \n",
      "\n",
      "tensor(3.4255e+12, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 6859233165312.0, avg_loss is 228641112064.0 \n",
      "\n",
      "tensor(2.0677e+11, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 936945254400.0, avg_loss is 31231508480.0 \n",
      "\n",
      "tensor(2.7722e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 514784886784.0, avg_loss is 17159496704.0 \n",
      "\n",
      "tensor(1.1402e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 470072918016.0, avg_loss is 15669097472.0 \n",
      "\n",
      "tensor(1.2036e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 460521046016.0, avg_loss is 15350701056.0 \n",
      "\n",
      "tensor(1.5813e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 457216262144.0, avg_loss is 15240542208.0 \n",
      "\n",
      "tensor(1.3069e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 460456722432.0, avg_loss is 15348557824.0 \n",
      "\n",
      "tensor(1.1927e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 456351088640.0, avg_loss is 15211703296.0 \n",
      "\n",
      "tensor(1.1279e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 454563168256.0, avg_loss is 15152105472.0 \n",
      "\n",
      "tensor(1.3159e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 455113441280.0, avg_loss is 15170448384.0 \n",
      "\n",
      "tensor(1.3320e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 456368291840.0, avg_loss is 15212276736.0 \n",
      "\n",
      "tensor(1.3856e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 454149046272.0, avg_loss is 15138301952.0 \n",
      "\n",
      "tensor(1.5332e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 458856824832.0, avg_loss is 15295227904.0 \n",
      "\n",
      "tensor(1.2425e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 458606706688.0, avg_loss is 15286890496.0 \n",
      "\n",
      "tensor(1.3714e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 455566426112.0, avg_loss is 15185547264.0 \n",
      "\n",
      "tensor(1.3965e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 462115078144.0, avg_loss is 15403836416.0 \n",
      "\n",
      "tensor(1.2168e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 459910545408.0, avg_loss is 15330351104.0 \n",
      "\n",
      "tensor(1.0788e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 458097033216.0, avg_loss is 15269901312.0 \n",
      "\n",
      "tensor(1.4357e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 457047703552.0, avg_loss is 15234923520.0 \n",
      "\n",
      "tensor(1.3405e+10, grad_fn=<MseLossBackward0>)\n",
      "\n",
      " test: \n",
      " total_loss is 456239808512.0, avg_loss is 15207993344.0 \n",
      "\n",
      "tensor(9.4343e+09, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     22\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_data:\n\u001b[0;32m     24\u001b[0m     values, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     25\u001b[0m     values\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m, in \u001b[0;36mhousedataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(data_features.values.shape)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(targets) \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries \u001b[38;5;28;01melse\u001b[39;00m targets\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 17\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# convert dataframe into tensor\u001b[39;00m\n\u001b[0;32m     18\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, targets\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(epochs):\n",
    "    house.train() # start the training model\n",
    "    for i, data in enumerate(train_data):\n",
    "        values, targets = data\n",
    "        values.to(device)\n",
    "        targets.to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        res = house(values)\n",
    "        targets = targets.reshape(res.shape)\n",
    "        train_loss = loss_fn(res, targets)\n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(train_loss)\n",
    "            \n",
    "    house.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = torch.tensor(0.0)\n",
    "        num = 0\n",
    "        for data in test_data:\n",
    "            values, targets = data\n",
    "            values.to(device)\n",
    "            targets.to(device)\n",
    "\n",
    "            res = house(values)\n",
    "            targets = targets.reshape(res.shape)\n",
    "            train_loss = loss_fn(res, targets)\n",
    "\n",
    "            total_loss += train_loss\n",
    "            num += 1\n",
    "        print(\"\\n test: \\n total_loss is {}, avg_loss is {} \\n\".format(total_loss, total_loss / num))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027f779-7993-431d-90ad-31a43470549b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
